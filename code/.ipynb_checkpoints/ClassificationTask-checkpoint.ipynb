{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Task\n",
    "\n",
    "In this assignment, you will:\n",
    "\n",
    "1. Propose a custom classification task and create a corpus of documents that are annotated for this task.\n",
    "\n",
    "2. Propose discriminative features to be included in the feature vector representation for the examples in this task and evaluate their utility by training and testing Logistic Regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Your Name Here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"blue\"> Submission Instructions</font>\n",
    "\n",
    "1. Click the Save button at the top of the Jupyter Notebook.\n",
    "2. Please make sure to have entered your name above.\n",
    "3. Select Cell -> All Output -> Clear. This will clear all the outputs from all cells (but will keep the content of ll cells). \n",
    "4. Select Cell -> Run All. This will run all the cells in order, and will take several minutes.\n",
    "5. Once you've rerun everything, select File -> Download as -> PDF via LaTeX and download a PDF version *.pdf* showing the code and the output of all cells, and save it in the same folder that contains the notebook file *.ipynb*.\n",
    "6. Look at the PDF file and make sure all your solutions are there, displayed correctly. The PDF is the only thing we will see when grading!\n",
    "7. Submit **both** your PDF and notebook on Canvas.\n",
    "8. Verify your Canvas submission contains the correct files by downloading them after posting them on Canvas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus acquisition and formatting\n",
    "\n",
    "1. Create a corpus of documents that you can use to create at least 300 examples for a task that is of interest you, a task that can be modeled as classification. In class we discussed the following NLP tasks:\n",
    "\n",
    "    - Document classification.\n",
    "    - Named entity recognition.\n",
    "    - Relation extraction.\n",
    "\n",
    "However you can choose any text processing task as long as it can be solved using classification.\n",
    "    \n",
    "- Manually annotate your data, such that you have at least 300 classification examples.\n",
    "- For manual annotation, you can use one of the schemes or annotation tools discussed in class.\n",
    "- The more data in your collection, the better your classification models will tend to perform on it.\n",
    "    \n",
    "\n",
    "2. Partition your data into three datasets: *train*, *dev*, and *test*, with the training set containing 80% of the documents, development 10%, and test 10%.\n",
    "\n",
    "    \n",
    "3. Your choice of task, documents, and labels is completely up to you. For example, if you choose to work on document classification, some possible sources of data are:\n",
    "\n",
    "    - **Project Gutenberg**: Metadata is available at this <a href=\"https://github.com/hugovk/gutenberg-metadata\">Github repo</a> along with URLs for the texts. Labels here can be author, subject, genre, etc.\n",
    "\t- **News articles**: Crawl news articles from different domains (e.g,. CNN, FoxNews); the label for each article is the domain.\n",
    "\t- **Movie summaries**: Labels here can be any categorical metadata aspect (genre, release date); note real-valued metadata (like box office, runtime) can be discretized by selecting some reasonable thresholds.\n",
    "\t- **Tweets**: Download your own tweets. Labels here can be any categorical metadata included in the tweet, or labels you add by hand (e.g., sarcasm).\n",
    "    \n",
    "    \n",
    "5. Additional requirements:\n",
    "\n",
    "    - No sentiment classification.\n",
    "    - **Undergraduate students**: It is acceptable to use an existing dataset, e.g. from kaggle.com or other repositories. However, it is preferable that you create your own dataset.\n",
    "    - **Graduate students**: It is highly recommended that you create your own dataset. This can also serve as the basis for your project, if you choose to submit a project instead of taking the final exam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task and Dataset description\n",
    "\n",
    "Describe your data. What is the source of the documents, and what do the labels mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// YOUR CONTRIBUTION HERE\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset reading and statistics\n",
    "\n",
    "\n",
    "Read the documents in each of the 3 datasets (*training*, *development*, and *test*) and for each dataset display the following statistics:\n",
    "\n",
    "1. The total number of examples in the dataset.\n",
    "2. The distribution of labels, which is task dependent. For example:\n",
    "    - For document classification, this would be the number of documents for each label.\n",
    "    - For NE recognition, this would be the number of names found for each NE type.\n",
    "    - For RE, this would be the total number of NE pairs in a sentence that are in the relationship (positive) or not (negative).\n",
    "\n",
    "For document classification, you can reuse the dataset reading code from the sentiment analysis assignments. For a different classification task, you would have to write different functions to read the data and the annotations. For example, if you use the Brat annotation tool, the annotations are stored in the `.ann` text files, which are straightforward to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"../data\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From textual examples to feature vectors\n",
    "\n",
    "Read the documents in each dataset (train, dev, test) and generate the corresponding examples as feature vectors. Some skeleton code is provided below, but feel free to customize as you see fit for your task.\n",
    "\n",
    "1. Tokenize each document using a spaCy tokenizer.\n",
    "\n",
    "2. Create at least two feature functions, and include them in the *features* list.\n",
    "\n",
    "    - A passing grade will be given to generic features that apply across arbitrary text classification problems (e.g., a feature for bigrams);\n",
    "\n",
    "    - A better grade will be given for features that reveal your own understanding of your data. What features do you think will help for your particular problem? Would features based on higher level NLP processing tasks (syntactic parsing, coreference resolution) be useful? Your grade is not tied to whether accuracy goes up or down, so be creative!\n",
    "\n",
    "    - You are free to read in any other external resources you like (dictionaries, document metadata, etc.), but make sure you include them in the `../data` folder.\n",
    "\n",
    "3. Process each dataset into a set of examples, by mapping each document in the dataset to its corresponding set of examples. Process each example into a feature vector, using the feature functions from *features*. You can reuse feature vector representation code from previous assignments.\n",
    "    - map example to a dictionary of feature names.\n",
    "    - map feature names to unique feature IDs.\n",
    "    - each example is a feature vector, where each feature ID is mapped to a feature value (e.g. word occurences)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from scipy import sparse\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create spaCy tokenizer.\n",
    "spacy_nlp = English()\n",
    "\n",
    "def spacy_tokenizer(text):\n",
    "    tokens = spacy_nlp.tokenizer(text)\n",
    "    \n",
    "    return [token.text for token in tokens]\n",
    "\n",
    "# YOUR CODE HERE\n",
    "features = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_examples(path, dataset, features):\n",
    "    instances = []\n",
    "    labels = []\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return instances, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate\n",
    "\n",
    "Write a `train_and_test` function that takes as input the training and test examples, trains a Logistic Regression model on the training examples and evaluates it on the test examples. You can use the default value for the `C` hyper-parameter, or tune it on the development examples. Report accuracy, or precision and recall, depending on the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(trainX, trainY, testX, testY):\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ablation experiments\n",
    "\n",
    "Evaluate the impact of your features by training and testing with vs. without each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify features to use. Do this multiple times, with and without any of the new features.\n",
    "features = []\n",
    "\n",
    "# Create training, development, and test examples\n",
    "trainX, trainY = create_examples(datapath, 'train', features)\n",
    "devX, devY = create_examples(datapath, 'dev', features)\n",
    "testX, testY = create_examples(datapath, 'test', features)\n",
    "\n",
    "# Evaluate LR model.\n",
    "train_and_test(trainX, trainY, testX, testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ROC or PR Curve\n",
    "\n",
    "*Mandatory for graduate students, optional for undergraduate students.*\n",
    "\n",
    "Take your best classifier and plot a <a href=\"https://en.wikipedia.org/wiki/Receiver_operating_characteristic\">Receiver Operating Characteristic (ROC)</a> curve if you use accuracy for evaluation, by varying a threshold on the probabilistic output. You can use the <a href=\"https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\">sklearn implementation</a>, or implement your own. If you use precision and recall, plot a precision vs. recall (PR) curve instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus points ##\n",
    "\n",
    "Anything extra goes here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis ##\n",
    "Include an analysis of the results that you obtained in the experiments above. It is improtant that results are formatted well, e.g. using tables, lists, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
